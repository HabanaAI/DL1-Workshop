{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet152 PyTorch Training on Gaudi\n",
    "\n",
    "In this notebook we will demonstrate how you can train the resnet152 image classifer using Pytorch. We will first demonstrate training on a single HPU, then on 8 HPUs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Set the python path environment variable and cd into appropriate directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env PYTHONPATH=/home/ubuntu/work/Model-References/PyTorch/computer_vision/classification/torchvision:/root/examples/models:/usr/lib/habanalabs/:/root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/ubuntu/work/Model-References/PyTorch/computer_vision/classification/torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries necessary for pytorch training and define the argument parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import utils\n",
    "\n",
    "def get_resnet152_argparser():\n",
    "    import argparse\n",
    "    import sys\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Classification Training')\n",
    "    parser.add_argument('--dl-time-exclude', default='True', type=lambda x: x.lower() == 'true', help='Set to False to include data load time')\n",
    "    parser.add_argument('-b', '--batch-size', default=128, type=int)\n",
    "    parser.add_argument('--device', default='hpu', help='device')\n",
    "    parser.add_argument('--epochs', default=90, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('-j', '--workers', default=10, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 10)')\n",
    "    parser.add_argument('--process-per-node', default=8, type=int, metavar='N',\n",
    "                        help='Number of process per node')\n",
    "    parser.add_argument('--hls_type', default='HLS1', help='Node type')\n",
    "    parser.add_argument('--lr', default=0.1, type=float, help='initial learning rate')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                        metavar='W', help='weight decay (default: 1e-4)',\n",
    "                        dest='weight_decay')\n",
    "\n",
    "    parser.add_argument('--print-freq', default=1, type=int, help='print frequency')\n",
    "    parser.add_argument('--output-dir', default='.', help='path where to save')\n",
    "\n",
    "    parser.add_argument('--channels-last', default='True', type=lambda x: x.lower() == 'true',\n",
    "                        help='Whether input is in channels last format.'\n",
    "                        'Any value other than True(case insensitive) disables channels-last')\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--seed', type=int, default=123, help='random seed')\n",
    "    parser.add_argument('--world-size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "    parser.add_argument('--num-train-steps', type=int, default=sys.maxsize, metavar='T',\n",
    "                        help='number of steps a.k.a iterations to run in training phase')\n",
    "    parser.add_argument('--num-eval-steps', type=int, default=sys.maxsize, metavar='E',\n",
    "                        help='number of steps a.k.a iterations to run in evaluation phase')\n",
    "    parser.add_argument('--save-checkpoint', action=\"store_true\",\n",
    "                        help='Whether or not to save model/checkpont; True: to save, False to avoid saving')\n",
    "    parser.add_argument('--run-lazy-mode', action='store_true',\n",
    "                        help='run model in lazy execution mode')\n",
    "    parser.add_argument('--deterministic', action=\"store_true\",\n",
    "                        help='Whether or not to make data loading deterministic;This does not make execution deterministic')\n",
    "    parser.add_argument('--hmp', dest='is_hmp', action='store_true', help='enable hmp mode')\n",
    "    parser.add_argument('--hmp-bf16', default='', help='path to bf16 ops list in hmp O1 mode')\n",
    "    parser.add_argument('--hmp-fp32', default='', help='path to fp32 ops list in hmp O1 mode')\n",
    "    parser.add_argument('--hmp-opt-level', default='O1', help='choose optimization level for hmp')\n",
    "    parser.add_argument('--hmp-verbose', action='store_true', help='enable verbose mode for hmp')\n",
    "\n",
    "    return parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main training function\n",
    "\n",
    "Uncomment the mark step code block in the appropriate places (after backward loss computation and after optimizer step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, optimizer, data_loader, device, epoch, print_freq):\n",
    "    model.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \",device=device)\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value}'))\n",
    "    metric_logger.add_meter('img/s', utils.SmoothedValue(window_size=10, fmt='{value}'))\n",
    "\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "    step_count = 0\n",
    "    last_print_time= time.time()\n",
    "\n",
    "    for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        image, target = image.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "\n",
    "        dl_ex_start_time=time.time()\n",
    "\n",
    "        if args.channels_last:\n",
    "            image = image.contiguous(memory_format=torch.channels_last)\n",
    "\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        #if args.run_lazy_mode:\n",
    "        #    import habana_frameworks.torch.core as htcore\n",
    "        #    htcore.mark_step()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        #if args.run_lazy_mode:\n",
    "        #    import habana_frameworks.torch.core as htcore\n",
    "        #    htcore.mark_step()\n",
    "\n",
    "        if step_count % print_freq == 0:\n",
    "            output_cpu = output.detach().to('cpu')\n",
    "            acc1, acc5 = utils.accuracy(output_cpu, target, topk=(1, 5))\n",
    "            batch_size = image.shape[0]\n",
    "            metric_logger.update(loss=loss.item(), lr=optimizer.param_groups[0][\"lr\"])\n",
    "            metric_logger.meters['acc1'].update(acc1.item(), n=batch_size*print_freq)\n",
    "            metric_logger.meters['acc5'].update(acc5.item(), n=batch_size*print_freq)\n",
    "            current_time = time.time()\n",
    "            last_print_time = dl_ex_start_time if args.dl_time_exclude else last_print_time\n",
    "            metric_logger.meters['img/s'].update(batch_size*print_freq / (current_time - last_print_time))\n",
    "            last_print_time = time.time()\n",
    "\n",
    "        step_count = step_count + 1\n",
    "        if step_count >= args.num_train_steps:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup necessary environment variables and command line arguments for single HPU resnet152 training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MAX_WAIT_ATTEMPTS\"] = \"50\"\n",
    "os.environ['HCL_CPU_AFFINITY'] = '1'\n",
    "os.environ['PT_HPU_ENABLE_SYNC_OUTPUT_HOST'] = 'false'\n",
    "parser = get_resnet152_argparser()\n",
    "   \n",
    "args = parser.parse_args([\"--batch-size\", \"256\", \"--epochs\", \"20\", \"--workers\", \"8\",\n",
    "\"--dl-time-exclude\", \"False\", \"--print-freq\", \"20\", \"--channels-last\", \"False\", \"--seed\", \"123\", \n",
    "\"--run-lazy-mode\", \"--hmp\",  \"--hmp-bf16\", \"/home/ubuntu/work/Model-References/PyTorch/computer_vision/classification/torchvision/ops_bf16_Resnet.txt\",\n",
    "\"--hmp-fp32\", \"/home/ubuntu/work/Model-References/PyTorch/computer_vision/classification/torchvision/ops_fp32_Resnet.txt\",\n",
    "\"--deterministic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main training code block for single node training. Use fake data to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Default 'fork' doesn't work with synapse. Use 'forkserver' or 'spawn'\n",
    "    torch.multiprocessing.set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "if args.is_hmp:\n",
    "    from habana_frameworks.torch.hpex import hmp\n",
    "    hmp.convert(opt_level=args.hmp_opt_level, bf16_file_path=args.hmp_bf16,\n",
    "                fp32_file_path=args.hmp_fp32, isVerbose=args.hmp_verbose)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if args.deterministic:\n",
    "    seed = args.seed\n",
    "    random.seed(seed)\n",
    "else:\n",
    "    seed = None\n",
    "\n",
    "device = torch.device('hpu')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "dataset = datasets.FakeData(transform=transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,]))\n",
    "dataset_test = datasets.FakeData(transform=transforms.Compose([transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,]))\n",
    "\n",
    "\n",
    "train_sampler = torch.utils.data.RandomSampler(dataset)\n",
    "test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "if args.workers > 0:\n",
    "    # patch torch cuda functions that are being unconditionally invoked\n",
    "    # in the multiprocessing data loader\n",
    "    torch.cuda.current_device = lambda: None\n",
    "    torch.cuda.set_device = lambda x: None\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=args.batch_size, sampler=train_sampler,\n",
    "    num_workers=args.workers, pin_memory=True, pin_memory_device='hpu')\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=args.batch_size, sampler=test_sampler,\n",
    "    num_workers=args.workers, pin_memory=True, pin_memory_device='hpu')\n",
    "\n",
    "\n",
    "print(\"Creating model\")\n",
    "model = torchvision.models.__dict__['resnet152'](pretrained=False)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if args.run_lazy_mode:\n",
    "    from habana_frameworks.torch.hpex.optimizers import FusedSGD\n",
    "    sgd_optimizer = FusedSGD\n",
    "else:\n",
    "    sgd_optimizer = torch.optim.SGD\n",
    "optimizer = sgd_optimizer(\n",
    "    model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "\n",
    "model_for_train = model\n",
    "\n",
    "\n",
    "print(\"Start training\")\n",
    "start_time = time.time()\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    train_one_epoch(model_for_train, criterion, optimizer, data_loader,\n",
    "            device, epoch, print_freq=args.print_freq)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print('Training time {}'.format(total_time_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Training\n",
    "\n",
    "**Restart the kernel before running the next section of the notebook**\n",
    "\n",
    "We will use the Model-References repository command line to demo distributed training on 8 HPUs. \n",
    "\n",
    "Distributed training differs in the following ways.\n",
    "\n",
    "1. [Initialization with hccl](https://github.com/HabanaAI/Model-References/blob/1.6.0/PyTorch/computer_vision/classification/torchvision/utils.py#L249)\n",
    "```\n",
    "    from habana_frameworks.torch.distributed.hccl import initialize_distributed_hpu\n",
    "    args.world_size, args.rank, args.local_rank = initialize_distributed_hpu()\n",
    "    ...\n",
    "    dist.init_process_group(backend='hccl', rank=args.rank, world_size=args.world_size)\n",
    "\n",
    "```\n",
    "\n",
    "2. [Use the torch distributed data sampler](https://github.com/HabanaAI/Model-References/blob/1.6.0/PyTorch/computer_vision/classification/torchvision/train.py#L179)\n",
    "```\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
    "```\n",
    "\n",
    "3. [Distributed data parallel pytorch model initalization](https://github.com/HabanaAI/Model-References/blob/1.6.0/PyTorch/computer_vision/classification/torchvision/train.py#L328)\n",
    "```\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, broadcast_buffers=False,\n",
    "            gradient_as_bucket_view=True)\n",
    "```\n",
    "\n",
    "__Note__: regarding Step 3 you must use the DistributedDataParallel API, as the DataParallel API is unsupported by Habana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env PYTHONPATH=/home/ubuntu/work/Model-References/PyTorch/computer_vision/classification/torchvision:/root/examples/models:/usr/lib/habanalabs/:/root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/ubuntu/work/Model-References/PyTorch/computer_vision/classification/torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the following patch to use fake data and remove evaluation (you can pass -R to git apply if you want to revert it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git apply /home/ubuntu/work/DL1-Workshop/PyTorch-ResNet152/fake_data_no_eval.patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following bash command as a shell script in the final cell(demo_resnet.sh) to start multi-HPU training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ```bash\n",
    "  export MASTER_ADDR=localhost\n",
    "  export MASTER_PORT=12355\n",
    "  mpirun -n 8 --bind-to core --map-by slot:PE=6 --rank-by core --report-bindings --allow-run-as-root \\\n",
    "    python3 train.py --model=resnet152 --device=hpu --batch-size=256 --epochs=90 --workers=10 \\\n",
    "    --dl-worker-type=MP --print-freq=10 --output-dir=. --seed=123 --hmp --hmp-bf16 ./ops_bf16_Resnet.txt \\\n",
    "    --hmp-fp32 ./ops_fp32_Resnet.txt --custom-lr-values 0.275 0.45 0.625 0.8 0.08 0.008 0.0008 \\\n",
    "    --custom-lr-milestones 1 2 3 4 30 60 80 --deterministic --dl-time-exclude=False\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sh /home/ubuntu/work/DL1-Workshop/PyTorch-ResNet152/demo_resnet.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "92265e7bf95517031b05ae8ffa1541004d740e0704a96d3b488bf9f3a9b868ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
