diff --git a/PyTorch/computer_vision/classification/torchvision/train.py b/PyTorch/computer_vision/classification/torchvision/train.py
index 6c924fc..b69d6ea 100644
--- a/PyTorch/computer_vision/classification/torchvision/train.py
+++ b/PyTorch/computer_vision/classification/torchvision/train.py
@@ -173,14 +173,19 @@ def load_data(traindir, valdir, cache_dataset, distributed):
         # Note that transforms are used only by native python data loader: torch.utils.data.DataLoader
         # and Aeon data loader. In case of MediaAPI, transforms are implemented independently using
         # API calls (see resnet_media_pipe.py code)
-        dataset = torchvision.datasets.ImageFolder(
-            traindir,
-            transforms.Compose([
-                transforms.RandomResizedCrop(224),
-                transforms.RandomHorizontalFlip(),
-                transforms.ToTensor(),
-                normalize,
-            ]))
+        #dataset = torchvision.datasets.ImageFolder(
+        #    traindir,
+        #    transforms.Compose([
+        #        transforms.RandomResizedCrop(224),
+        #        transforms.RandomHorizontalFlip(),
+        #        transforms.ToTensor(),
+        #        normalize,
+        #    ]))
+        dataset = torchvision.datasets.CIFAR10(root=traindir, train=True,
+                                        download=True,
+                                        transform=transforms.Compose(
+                                                        [transforms.ToTensor(),
+                                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))
         if cache_dataset:
             print("Saving dataset_train to {}".format(cache_path))
             utils.mkdir(os.path.dirname(cache_path))
@@ -195,14 +200,19 @@ def load_data(traindir, valdir, cache_dataset, distributed):
         dataset_test, _ = torch.load(cache_path)
     else:
         # Transforms are not used by MediaAPI data loader. See comment above for 'dataset' transforms.
-        dataset_test = torchvision.datasets.ImageFolder(
-            valdir,
-            transforms.Compose([
-                transforms.Resize(256),
-                transforms.CenterCrop(224),
-                transforms.ToTensor(),
-                normalize,
-            ]))
+        #dataset_test = torchvision.datasets.ImageFolder(
+        #    valdir,
+        #    transforms.Compose([
+        #        transforms.Resize(256),
+        #        transforms.CenterCrop(224),
+        #        transforms.ToTensor(),
+        #        normalize,
+        #    ]))
+        dataset_test = torchvision.datasets.CIFAR10(root=valdir, train=False,
+                                                download=True,
+                                                transform=transforms.Compose(
+                                                    [transforms.ToTensor(),
+                                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))
         if cache_dataset:
             print("Saving dataset_test to {}".format(cache_path))
             utils.mkdir(os.path.dirname(cache_path))
@@ -460,8 +470,8 @@ def main(args):
                 device, epoch, print_freq=train_print_freq, apex=args.apex,
                 tb_writer=tb_writer, steps_per_epoch=steps_per_epoch, is_autocast=args.is_autocast)
         if epoch == next_eval_epoch:
-            evaluate(model_for_eval, criterion, data_loader_test, device=device,
-                    print_freq=eval_print_freq, tb_writer=tb_writer, epoch=epoch, is_autocast=args.is_autocast)
+            #evaluate(model_for_eval, criterion, data_loader_test, device=device,
+            #        print_freq=eval_print_freq, tb_writer=tb_writer, epoch=epoch, is_autocast=args.is_autocast)
             next_eval_epoch += args.epochs_between_evals

         if args.output_dir and args.save_checkpoint:
