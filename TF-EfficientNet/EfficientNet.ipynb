{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84709c2a-1e7b-45b7-b889-8559742ca716",
   "metadata": {
    "tags": []
   },
   "source": [
    "Copyright (c) 2023 Habana Labs, Ltd. an Intel Company.<br>\n",
    "Copyright (c) 2019 The TensorFlow Authors.\n",
    "\n",
    "## Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d530e585",
   "metadata": {},
   "source": [
    "# Migrating TensorFlow EfficientNet to Habana Gaudi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a928f",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, we will learn how to migrate EfficientNet in public TensorFlow [models](https://github.com/tensorflow/models) repository to Habana Gaudi device with very limited code changes. We will first verify the model can be trained on CPU. Then add code to the training script to enable it on a single HPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f7b224",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c4547",
   "metadata": {},
   "source": [
    "First of all, check the current directory to prepare for cloning TensorFlow model's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71532f",
   "metadata": {},
   "source": [
    "Then, we will clone TensorFlow [models](https://github.com/tensorflow/models.git)  repository v2.11.0 to the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95020dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --depth 1 --branch v2.11.0 https://github.com/tensorflow/models.git   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b7252",
   "metadata": {},
   "source": [
    "Verify if the repository was cloned successfully in the current location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef3a92",
   "metadata": {},
   "source": [
    "Check if the current PYTHONPATH contains TensorFlow `models` location. If not, add it. \n",
    "\n",
    "The following command assumes the models repository location is at `/home/ubuntu/work/DL1-Workshop/TF-EfficientNet` folder. Modify it accordingly if it is in a different location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env PYTHONPATH=/root/DL1-Workshop/TF-EfficientNet/models:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e40bce",
   "metadata": {},
   "source": [
    "Install the depedent packages for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faee1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install tensorflow-model-optimization tensorflow_addons gin-config tensorflow_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380117c5",
   "metadata": {},
   "source": [
    "### Training on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd81de",
   "metadata": {},
   "source": [
    "We will be using Keras EfficientNet at https://github.com/tensorflow/models/tree/v2.9.2/official/legacy/image_classification as the example to show how to enable a public model on Habana Gaudi device. \n",
    "\n",
    "EfficientNet is a convolutional neural network architecture and scaling method that uniformly scales all dimensions of depth/width/resolution using a compound coefficient. The model was first introduced by Tan et al. in [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946).  In this session, we are going to use EfficientNet baseline model EfficientNet-B0 as the training example.\n",
    "\n",
    "First of all, let's enable the training with synthetic data on CPU and check its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd models/official/legacy/image_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ceac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5119e30a",
   "metadata": {},
   "source": [
    "Let's first verify if EfficientNet can be run on CPU with the existing code from `models` repository.\n",
    "\n",
    "In TensorFlow `models` repository, there are only EfficientNet configuration files for GPU and TPU under `configs` folder. We will use the following Python command to override the existing configurations for GPU and run EfficientNet-B0 on CPU:\n",
    "\n",
    "```\n",
    "python3 classifier_trainer.py --mode=train_and_eval --model_type=efficientnet --dataset=imagenet --model_dir=./log_cpu --data_dir=./ --config_file=configs/examples/efficientnet/imagenet/efficientnet-b0-gpu.yaml --params_override='runtime.num_gpus=0,runtime.distribution_strategy=\"off\",train_dataset.builder=\"synthetic\",validation_dataset.builder=\"synthetic\",train.steps=1000,train.epochs=1,evaluation.skip_eval=True'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100693cc",
   "metadata": {},
   "source": [
    "The Efficient-B0 training results on CPU look as below:\n",
    "\n",
    "<img src=\"./enet_cpu_results.png\" alt=\"efficientnet_config\" align=\"left\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fbefa6",
   "metadata": {},
   "source": [
    "From the output log above, we can see that the throughput for EfficientNet-B0 training on CPU with synthetic data is around `40 examples/sec`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acb2b87",
   "metadata": {},
   "source": [
    "### Training on 1 HPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4212d",
   "metadata": {},
   "source": [
    "Now, let's modify the traning script and enable the model on Habana Gaudi device with **BF16** data type. With environment variable **`TF_ENABLE_BF16_CONVERSION=1`**, EfficientNet is trained with BF16 data type.\n",
    "\n",
    "Open [models/official/legacy/image_classification/classifier_trainer.py](models/official/legacy/image_classification/classifier_trainer.py) and insert the following 2 lines of code in **line 444**:\n",
    "\n",
    "```\n",
    "  from habana_frameworks.tensorflow import load_habana_module\n",
    "  load_habana_module()\n",
    "```\n",
    "\n",
    "**Optionally**, if you want to reduce the verbosity of the training process, modify **line 452** from `logging.INFO` to `logging.ERROR`:\n",
    "\n",
    "```\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "```\n",
    "\n",
    "To display the throughput during the training process, in **line 388**, insert the following statement:\n",
    "\n",
    "```\n",
    "logging.set_verbosity(logging.INFO)\n",
    "```\n",
    "\n",
    "Save the file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf16a89",
   "metadata": {},
   "source": [
    "These 2 lines code will load Habana software modules in the beginning of training, and aquire Habana Gaudi device and register the device to TensorFlow. This is all you need to do to enable EfficientNet on HPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf7b55b",
   "metadata": {},
   "source": [
    "Now, let's run the same command as above to launch the training. This time EfficientNet will be trained on a single HPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f63754",
   "metadata": {},
   "outputs": [],
   "source": [
    "!TF_ENABLE_BF16_CONVERSION=1 python3 classifier_trainer.py --mode=train_and_eval --model_type=efficientnet --dataset=imagenet --model_dir=./log_hpu --data_dir=./ --config_file=configs/examples/efficientnet/imagenet/efficientnet-b0-gpu.yaml --params_override='runtime.num_gpus=0,runtime.distribution_strategy=\"off\",train_dataset.builder=\"synthetic\",validation_dataset.builder=\"synthetic\",train.steps=1000,train.epochs=1,evaluation.skip_eval=True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdcf668",
   "metadata": {},
   "source": [
    "From the output log above, we can see that the throughput for EfficientNet-B0 training on Habana Gaudi with synthetic data is around `658 examples/sec`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25e5178",
   "metadata": {},
   "source": [
    "### Distributed Training on 8 HPUs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57863c60",
   "metadata": {},
   "source": [
    "Now, let's enable the distributed training for EfficientNet on 8 HPUs of DLAMI.\n",
    "\n",
    "In the original source code, `tf.distribute.Strategy` is used to support the distributed training for TPU and GPU. We will re-use this architecture and enable the distributed training on multi-HPUs with `HPUStrategy`. `HPUStrategy` was built based on `MultiWorkerMirroredStrategy`, in which each worker runs in a separate process and with a single Gaudi device acquired.\n",
    "\n",
    "* According to our [collateral](https://docs.habana.ai/en/latest/Tensorflow_Scaling_Guide/TensorFlow_Gaudi_Scaling_Guide.html#multi-worker-training-using-hpustrategy), we will first construct HPUStrategy instance when `distribution_strategy` parameter is set to `hpu`.\n",
    "\n",
    "    Click [models/official/common/distribute_utils.py](models/official/common/distribute_utils.py) and in **line 148**, insert the following code:\n",
    "\n",
    "    ```\n",
    "    if distribution_strategy == \"hpu\":\n",
    "      from habana_frameworks.tensorflow.distribute import HPUStrategy\n",
    "      return HPUStrategy()\n",
    "    ```\n",
    "    \n",
    "    And save the file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd75f4d",
   "metadata": {},
   "source": [
    "* Then we will configure **`TF_CONFIG`** environment variable by re-using the existing `distribute_utils.configure_cluster()` function in the code:\n",
    "  \n",
    "  Open [models/official/legacy/image_classification/classifier_trainer.py](models/official/vision/image_classification/classifier_trainer.py) and replace **line 293 and 294** with following code:\n",
    "\n",
    "  ```\n",
    "    if params.runtime.distribution_strategy == 'hpu':\n",
    "      hls_addresses = [\"127.0.0.1\"]\n",
    "      TF_BASE_PORT = 2410\n",
    "      from habana_frameworks.tensorflow.multinode_helpers import comm_size, comm_rank\n",
    "      mpi_rank = comm_rank()\n",
    "      mpi_size = comm_size()\n",
    "\n",
    "      worker_hosts = \",\".join([\",\".join([address + ':' + str(TF_BASE_PORT + rank)\n",
    "                                         for rank in range(mpi_size // len(hls_addresses))])\n",
    "                               for address in hls_addresses])\n",
    "      task_index = mpi_rank\n",
    "      distribute_utils.configure_cluster(worker_hosts, task_index)\n",
    "    else:\n",
    "      distribute_utils.configure_cluster(params.runtime.worker_hosts,\n",
    "                                         params.runtime.task_index)\n",
    "  ```\n",
    "\n",
    "    Save the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c512e",
   "metadata": {},
   "source": [
    "Now we launch 8 processes with mpirun command to start the distributed training for EfficientNet on 8 HPUs with `HPUStrategy`:\n",
    "\n",
    "```\n",
    "mpirun --allow-run-as-root -np 8 -x TF_ENABLE_BF16_CONVERSION=1 python3 classifier_trainer.py --mode=train_and_eval --model_type=efficientnet --dataset=imagenet --model_dir=./log_hpu_8 --data_dir=./ --config_file=configs/examples/efficientnet/imagenet/efficientnet-b0-gpu.yaml --params_override='runtime.num_gpus=0,runtime.distribution_strategy=\"hpu\",train_dataset.builder=\"synthetic\",validation_dataset.builder=\"synthetic\",train.steps=1000,train.epochs=1,evaluation.skip_eval=True'\n",
    "\n",
    "```\n",
    "\n",
    "Run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a39cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun --allow-run-as-root -np 8 -x TF_ENABLE_BF16_CONVERSION=1 python3 classifier_trainer.py --mode=train_and_eval --model_type=efficientnet --dataset=imagenet --model_dir=./log_hpu_8 --data_dir=./ --config_file=configs/examples/efficientnet/imagenet/efficientnet-b0-gpu.yaml --params_override='runtime.num_gpus=0,runtime.distribution_strategy=\"hpu\",train_dataset.builder=\"synthetic\",validation_dataset.builder=\"synthetic\",train.steps=1000,train.epochs=1,evaluation.skip_eval=True,train.callbacks.enable_checkpoint_and_export=False'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7932bc",
   "metadata": {},
   "source": [
    "From the output above, you can see that with 8 Gaudi cards, the training throughput is significantly improved to around 3962 images/sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb6964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "92265e7bf95517031b05ae8ffa1541004d740e0704a96d3b488bf9f3a9b868ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
